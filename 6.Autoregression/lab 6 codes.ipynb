{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296129ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae88973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"daily_covid_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214be5ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6fe67cd28dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# storing the new cases data in a variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0my_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_cases'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# now let's plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 1\"\"\"\n",
    "\n",
    "'''part(a)'''\n",
    "# making list for xticks\n",
    "xticks_points = [21]; # for 20th feb\n",
    "\n",
    "# now will iterate by two months till oct\n",
    "for i in range(10):\n",
    "    xticks_points.append(xticks_points[i] + 60);\n",
    "    \n",
    "# now creating labels for these points\n",
    "xticks_labels = ['Feb-20', 'Apr-20', 'Jun-20', 'Aug-20', 'Oct-20', 'Dec-20', 'Feb-21', 'Apr-21', 'Jun-21', 'Aug-21', 'Oct-21']\n",
    "\n",
    "# storing the new cases data in a variable\n",
    "y_vals = df['new_cases']\n",
    "\n",
    "# now let's plot\n",
    "fig = plt.figure(figsize = (20, 10));\n",
    "plt.plot(y_vals)\n",
    "plt.xticks(xticks_points, xticks_labels, fontsize = 12)\n",
    "plt.xlabel('Month-Year', fontsize = 14)\n",
    "plt.ylabel('New Confirmed Cases', fontsize = 14)\n",
    "plt.title('New Confirmed Cases vs Month-Year', fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "def create_lag(data, lag):\n",
    "    return df.iloc[:(data.shape[0] - lag), :];\n",
    "\n",
    "'''part(b)'''\n",
    "# getting the number of rows\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "# storing the lag series 0 and 1\n",
    "lag_series_0 = df.iloc[1:num_rows, :];\n",
    "lag_series_1 = create_lag(df, 1)\n",
    "\n",
    "# calculating the correlation between them and showing the result\n",
    "print(\"The Pearson  correlation  (autocorrelation)  coefficient  between  \\nthe  generated  one-day  lag  time \\\n",
    "sequence and the given time sequence : \", format(lag_series_0['new_cases'].corr(lag_series_1['new_cases']),'.3f'))\n",
    "\n",
    "'''part(c)'''\n",
    "# since we have all the required data so plotting the things accordingly''''''\n",
    "plt.scatter(lag_series_0['new_cases'], lag_series_1['new_cases'], s = 5, c = 'g')\n",
    "plt.title(\"no lag series vs one-day lagged series\", fontsize = 14)\n",
    "plt.xlabel(\"no lag series\", fontsize = 12)\n",
    "plt.ylabel(\"one-day lagged series\", fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "'''part(d)'''\n",
    "\n",
    "# creating two arrays, one will contain lag series and other correspoding original series \n",
    "# as we have to slice the data according to lag coeff that's why necessary\n",
    "lag_series = []; corr_original_series = []\n",
    "\n",
    "# storing the lag coefficients\n",
    "lag_val = (1,2,3,4,5,6)\n",
    "for i in lag_val:\n",
    "    lag_series.append(create_lag(df,i));\n",
    "    corr_original_series.append(df.iloc[i:, :])\n",
    "\n",
    "# creating an array to store the correspoding correlation wrt lag val\n",
    "corr_correlation = [];\n",
    "for i in lag_val:\n",
    "    corr_correlation.append(lag_series[i - 1]['new_cases'].corr(corr_original_series[i-1]['new_cases']))\n",
    "    \n",
    "# plotting lag coefficients vs corresponding correlation using scatter plot\n",
    "plt.scatter(lag_val, corr_correlation, s = 20, c = 'g')\n",
    "plt.xlabel('Lag number')\n",
    "plt.ylabel('Corresponding correlation')\n",
    "plt.title('Correlation coefficient vs lag value')\n",
    "plt.show()\n",
    "\n",
    "'''part(e)'''\n",
    "# plotting corelogram using plot_acf function\n",
    "statMod.graphics.tsa.plot_acf(df['new_cases'],lags=lag_val)\n",
    "plt.xlabel('days lagged')\n",
    "plt.ylabel('Corresponding Correlation coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e22413",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7219bf49e378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.35\u001b[0m \u001b[1;31m# 35% for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtst_sz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtst_sz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtst_sz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 2\"\"\"\n",
    "\n",
    "series = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lab assgn 6/daily_covid_cases.csv', parse_dates=['Date'], index_col=['Date'], sep=',')     \n",
    "\n",
    "test_size = 0.35 # 35% for testing \n",
    "X = series.values \n",
    "tst_sz = math.ceil(len(X)*test_size) \n",
    "train, test = X[:len(X)-tst_sz], X[len(X)-tst_sz:]\n",
    "\n",
    "'''Part(a)'''\n",
    "p = 5;\n",
    "ar_model = AR(train, lags = p)\n",
    "AR_model = ar_model.fit()\n",
    "coef = AR_model.params\n",
    "print('The coefficient for lag 5 series are : \\n', coef)\n",
    "\n",
    "'''part(b)'''\n",
    "\n",
    "history = train[len(train)-p:] \n",
    "history = [history[i] for i in range(len(history))] \n",
    "predictions = list() # List to hold the predictions, 1 step at a time \n",
    "for t in range(len(test)): \n",
    "    length = len(history) \n",
    "    lag = [history[i] for i in range(length-p,length)] \n",
    "    yhat = coef[0]  # Initialize to w0 \n",
    "    for d in range(p): \n",
    "    yhat += coef[d+1] * lag[p-d-1]  # Add other values \n",
    "    obs = test[t] \n",
    "    predictions.append(yhat)  #Append  predictions  to  compute  RMSE later \n",
    "    history.append(obs)  # Append actual test value to history, to be used in next step.\n",
    "\n",
    "'''part(b(i))'''\n",
    "# scatter plot in b/w actual and predicted values\n",
    "plt.scatter(predictions, test, s = 5, c = 'g')\n",
    "plt.xlabel('Predicted Values', fontsize = 12)\n",
    "plt.ylabel('Actual Values', fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "'''part(b(ii))'''\n",
    "plt.plot(test, label = ['Actual data'])\n",
    "plt.plot(predictions, label = ['Predicted data'])\n",
    "plt.legend()\n",
    "plt.xlabel('Time points')\n",
    "plt.ylabel('New cases')\n",
    "plt.show()\n",
    "\n",
    "'''part(b(iii))'''\n",
    "rmse_b_iii =( math.sqrt(mean_squared_error(test, predictions))/np.mean(test) )* 100\n",
    "print(\"RMSE % is : \", format(rmse_b_iii, '.3f'))\n",
    "\n",
    "'''part(b(iv))'''\n",
    "mape_b_iv = np.mean( np.abs( (test - predictions)/test) ) * 100\n",
    "print(\"Mape is : \", format(mape_b_iv, '.3f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3c1401",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-085740203b77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Question 3\"\"\"\n",
    "\n",
    "lag_val2 = (1, 5, 10, 15, 25)\n",
    "rmse_3 = list()\n",
    "mape_3 = list()\n",
    "\n",
    "# let's loop through each lag days and get the corresponding result by creating the model\n",
    "for p in lag_val2:\n",
    "    ar_model = AR(train, lags=p)\n",
    "    AR_model = ar_model.fit()\n",
    "    coef = AR_model.params\n",
    "    history = train[len(train)-p:] \n",
    "    history = [history[i] for i in range(len(history))] \n",
    "    predictions = list() # List to hold the predictions, 1 step at a time \n",
    "    for t in range(len(test)): \n",
    "        length = len(history) \n",
    "        lag = [history[i] for i in range(length-p,length)] \n",
    "        yhat = coef[0]  # Initialize to w0 \n",
    "    for d in range(p): \n",
    "        yhat += coef[d+1] * lag[p-d-1]  # Add other values \n",
    "    obs = test[t] \n",
    "    predictions.append(yhat)  #Append  predictions  to  compute  RMSE later \n",
    "    history.append(obs)  # Append actual test value to history, to be used in next step.\n",
    "\n",
    "    # RMSE calculation and storing in rmse_3\n",
    "    rmse_calculated =( math.sqrt(mean_squared_error(test, predictions))/np.mean(test) )* 100\n",
    "    rmse_3.append(rmse_calculated)\n",
    "\n",
    "    # mape calculation and storing in mape_3\n",
    "    mape_calculated = np.mean( np.abs( (test - predictions)/test) ) * 100\n",
    "    mape_3.append(mape_calculated)\n",
    "\n",
    "# Creating bar chart b/w rmse values and lag values\n",
    "plt.bar(lag_val2, rmse_3)\n",
    "plt.xlabel('Lag values')\n",
    "plt.ylabel('Corresponding RMSE(%)')\n",
    "plt.show()\n",
    "\n",
    "# Creating bar chart b/w mape values and lag values\n",
    "plt.bar(lag_val2, mape_3, color = 'g')\n",
    "plt.xlabel('Lag values')\n",
    "plt.ylabel('Corresponding Mape values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 4\"\"\"\n",
    "\n",
    "# calculating optimum value of lag\n",
    "p = 1;\n",
    "train_data = list()\n",
    "for i in range(train.shape[0]):\n",
    "    train_data.append(train[i][0])\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "while(p < len(train_data)):\n",
    "    corr_value = np.corrcoef(train_data[:len(train_data) - p], train_data[p:])\n",
    "    p = p + 1;\n",
    "    if(abs(corr_value[0,1]) <= 2/math.sqrt(train_data.shape[0] - p)):\n",
    "        print(\"The optimum value for lag is : \", p)\n",
    "        break;\n",
    "  \n",
    "# Creating AR model with the above calculated optimum value of p\n",
    "ar_model = AR(train, lags=p)\n",
    "AR_model = ar_model.fit()\n",
    "coef = AR_model.params\n",
    "history = train[len(train)-p:] \n",
    "history = [history[i] for i in range(len(history))] \n",
    "predictions = list() # List to hold the predictions, 1 step at a time \n",
    "\n",
    "for t in range(len(test)): \n",
    "    length = len(history) \n",
    "    lag = [history[i] for i in range(length-p,length)] \n",
    "    yhat = coef[0]  # Initialize to w0 \n",
    "    for d in range(p): \n",
    "        yhat += coef[d+1] * lag[p-d-1]  # Add other values \n",
    "    obs = test[t] \n",
    "    predictions.append(yhat)  #Append  predictions  to  compute  RMSE later \n",
    "    history.append(obs)  # Append actual test value to history, to be used in next step.\n",
    "\n",
    "# RMSE calculation\n",
    "rmse_calculated =( math.sqrt(mean_squared_error(test, predictions))/np.mean(test) )* 100\n",
    "print('RMSE(%) is : ', format(rmse_calculated, '.3f'))\n",
    "\n",
    "# MAPE calculation\n",
    "mape_calculated = np.mean( np.abs( (test - predictions)/test) ) * 100\n",
    "print('MAPE is : ', format(mape_calculated, '.3f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
